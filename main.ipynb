{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task!\n",
    "The task is to create a classifier for cancer diagnose (malignant or benign)\n",
    "\n",
    "\n",
    "\n",
    "#### Goal \n",
    "To get familar with (installation and usage) Jupyter notebook and machine learning library Sklearn (https://scikit-learn.org/stable/) by applying four different classification algorithms (KNN, Logistic Regression, SVM, Decision Tree) on the same task.  Additionally, you also call functions for data scaling, regularization, and kernel function.\n",
    "#### Dataset\n",
    "Breast Cancer Wisconsin (Diagnostic) Database.\n",
    "https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['malignant', 'benign']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "#print the predicton labels (target names)\n",
    "list(cancer.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize our data\n",
    "label_names = cancer['target_names']\n",
    "labels = cancer['target']\n",
    "feature_names = cancer['feature_names']\n",
    "features = cancer['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "569\n",
      "30\n",
      "569\n"
     ]
    }
   ],
   "source": [
    "# see the data\n",
    "print (label_names) \n",
    "print (len(labels))\n",
    "print (len(feature_names))\n",
    "print (len(features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover the data to gain insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-1: output the number of features the breast cancer dataset has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    "print(len(feature_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-2: output the size of the data set (how many instances/sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-3: output the number of instances of malignant and the number of instances of benign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'malignant': 0, 'benign': 0}\n",
      "{'malignant': 212, 'benign': 357}\n"
     ]
    }
   ],
   "source": [
    "instance_dic={}\n",
    "for i in label_names:\n",
    "    instance_dic[i]=0\n",
    "print(instance_dic)\n",
    "\n",
    "for i in labels:\n",
    "    instance_dic[label_names[i]]+=1\n",
    "    \n",
    "print(instance_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny practice to prepare training and test data for algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will split dataset into training dataset (x) and testing dataset (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import train_test_split from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our data with traing data test_size=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question（no coding need）: Is above split of training/testing is random? How to make the training and test data fixed, so you can reproduce your results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "answer: I understand that the train_test_split method splits a dataset into random train and test subsets. Although,we can get same splits using an optional argument *random_state = int*\n",
    "\n",
    "\n",
    "For example: X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3 , random_state=7)\n",
    "\n",
    "\n",
    "Note- The int value assigned to random_state should be fixed and not be changed to get same split in dataset everytime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we just finish some warming excercises, in the following, we will train four different classifier and use them to do cancer prediction respectively.\n",
    "\n",
    "## General Learning Process\n",
    "#### 1. load the data and prepare the data\n",
    "#### 2. Implement an algorithm\n",
    "#### 3. Train the algorithm, verify accuracy, and optimize.\n",
    "#### 4. Predict on test data.\n",
    "#### 5. Output the prediction performance\n",
    "\n",
    "Note that in this assigment, you are not requied to implment the classifiction algorithms, which are already implemented in backend in sklearn library, you just call the function to run the required task. It is your responsibility to explore which function can be used and should be used to implement the TASKS below.  Furthermore, feel free to explore new functions though not mandatory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm1: KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### okay, now let's asume we start from scratch to use KNN for this classification task. \n",
    "#### Task-4: load cancer data as you did in above warming excercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-5: split data into training data and test data, keep training/test size as default, but specify a fixed value for random_state yourself. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3 , random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select an algorithm\n",
    "#### Train KNN model using KNeighborsClassifier in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We predict cancer on the test data using the trained KNN and output the prediction results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0 0 1 0 0 1 1 1 1 1 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 0 1 0 1 1 1 1 1 0\n",
      " 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 1 0 1 1 1 1 1 0 0 1 1 1 1 1 1\n",
      " 1 0 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 1\n",
      " 0 1 1 1 1 0 1 1 1 0 0 0 0 1 1 1 0 1 1 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "prediction = knn.predict(X_test)\n",
    "print (prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we output the accuracies of the trained KNN model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447236180904522\n",
      "0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "print (knn.score(X_train, y_train))\n",
    "print (knn.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-6: round down the floats to two decimals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.94\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "print(round(knn.score(X_train, y_train), 2))\n",
    "print(round(knn.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we are going to do some optimization, to explore the best N value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-7: print out the value of N in your above trianed KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(knn.n_neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-8: try different N (e.g., [1,10]), and print out the accuracy when N is applied with different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For value of N =  1\n",
      "Train accuracy = 1.0\n",
      "Test accuracy  = 0.92\n",
      "==============================\n",
      "For value of N =  2\n",
      "Train accuracy = 0.97\n",
      "Test accuracy  = 0.89\n",
      "==============================\n",
      "For value of N =  3\n",
      "Train accuracy = 0.96\n",
      "Test accuracy  = 0.92\n",
      "==============================\n",
      "For value of N =  4\n",
      "Train accuracy = 0.95\n",
      "Test accuracy  = 0.91\n",
      "==============================\n",
      "For value of N =  5\n",
      "Train accuracy = 0.94\n",
      "Test accuracy  = 0.95\n",
      "==============================\n",
      "For value of N =  6\n",
      "Train accuracy = 0.94\n",
      "Test accuracy  = 0.95\n",
      "==============================\n",
      "For value of N =  7\n",
      "Train accuracy = 0.94\n",
      "Test accuracy  = 0.95\n",
      "==============================\n",
      "For value of N =  8\n",
      "Train accuracy = 0.94\n",
      "Test accuracy  = 0.95\n",
      "==============================\n",
      "For value of N =  9\n",
      "Train accuracy = 0.93\n",
      "Test accuracy  = 0.96\n",
      "==============================\n",
      "For value of N =  10\n",
      "Train accuracy = 0.94\n",
      "Test accuracy  = 0.95\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for N in range(1, 10+1):\n",
    "    print(\"For value of N = \",N)\n",
    "    knn = KNeighborsClassifier(n_neighbors=N)\n",
    "    knn.fit(X_train, y_train)\n",
    "    print(\"Train accuracy =\", round(knn.score(X_train, y_train), 2))\n",
    "    print(\"Test accuracy  =\", round(knn.score(X_test, y_test),2))\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm2: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-9: Split the data into training data and test data as you did above, this time try to not copy but write the code yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3 , random_state=7)\n",
    "\n",
    "##I took same value of random_state as before so as to get Logistic regression accuracy for same test cases and test cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-10: Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=2800,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#training\n",
    "\n",
    "log_reg = LogisticRegression(max_iter = 2800)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below we predict cancer on the test data using the trained logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-11: print out the accuracies of the trained  logistic regression model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.96\n",
      "Test accuracy  = 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy =\", round(log_reg.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(log_reg.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "#### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-12: Train a logistic regression model by modifying the regularization parameter C to different values (e.g., 100), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for value of C =  1\n",
      "Training for value of C =  10\n",
      "Training for value of C =  50\n",
      "Training for value of C =  100\n",
      "Training for value of C =  1000\n",
      "Training for value of C =  1500\n"
     ]
    }
   ],
   "source": [
    "log_regs={}\n",
    "list_of_c = [1,10,50,100,1000,1500]\n",
    "for c in list_of_c:\n",
    "    print(\"Training for value of C = \",c)\n",
    "    log_reg = LogisticRegression(C=c , max_iter = 10000)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    log_regs[c]=log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-13: print the corresponding training and testing accuracy to see the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value of C =  1\n",
      "Train accuracy = 0.96\n",
      "Test accuracy  = 0.96\n",
      "==============================\n",
      "Value of C =  10\n",
      "Train accuracy = 0.97\n",
      "Test accuracy  = 0.95\n",
      "==============================\n",
      "Value of C =  50\n",
      "Train accuracy = 0.98\n",
      "Test accuracy  = 0.97\n",
      "==============================\n",
      "Value of C =  100\n",
      "Train accuracy = 0.98\n",
      "Test accuracy  = 0.97\n",
      "==============================\n",
      "Value of C =  1000\n",
      "Train accuracy = 0.99\n",
      "Test accuracy  = 0.96\n",
      "==============================\n",
      "Value of C =  1500\n",
      "Train accuracy = 0.99\n",
      "Test accuracy  = 0.96\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for c in log_regs:\n",
    "    log_reg=log_regs[c]\n",
    "    print(\"Value of C = \",c)\n",
    "    print(\"Train accuracy =\", round(log_reg.score(X_train, y_train), 2))\n",
    "    print(\"Test accuracy  =\", round(log_reg.score(X_test, y_test),2))\n",
    "    print(\"==============================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-14: Lower the regularization parameter C as 0.01, and print out the corresponding training and testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.95\n",
      "Test accuracy  = 0.96\n"
     ]
    }
   ],
   "source": [
    "c= 0.01\n",
    "log_reg = LogisticRegression(C = c , max_iter = 10000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"Train accuracy =\", round(log_reg.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(log_reg.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm3: SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are loading data and splitting data into training data and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, random_state=0)\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-15:  train a SVM model using SVC model in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC \n",
    "\n",
    "#codes to train a SVM model\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We predict cancer on the test data using the trained SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-16: output the accuracy of the training and prediction respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.98\n",
      "Test accuracy  = 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy =\", round(svm.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(svm.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimization by using kernel function\n",
    "#### Task-17: print the name of the default kernel function in above model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n"
     ]
    }
   ],
   "source": [
    "print(svm.kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, now we will have a little bit harder nut to crack :-) \n",
    "#### Task-18:  implement two kernel functions (linear and Gaussian) on your own and test the different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=linear\n",
    "def my_kernel_linear(xi,xj):\n",
    "    \n",
    "    # write a linear kernel function here\n",
    "    l = np.dot(xi,np.transpose(xj))\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel=Gaussian = RBF\n",
    "def my_kernel_gaussian(xi,xj):\n",
    "    \n",
    "     # write a gaussian kernel function\n",
    "    K = np.zeros((xi.shape[0],xj.shape[0]))\n",
    "    for i,x in enumerate(xi):\n",
    "        for j,y in enumerate(xj):\n",
    "            K[i,j] = np.exp(-1*np.linalg.norm(x-y)**2)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are replacing replace the default kernel function with your kernel.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "    kernel=<function my_kernel_linear at 0x00000232600D8828>, max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_linear_kernel = SVC(kernel=my_kernel_linear)\n",
    "svm_linear_kernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-19: print out the accuracy  of SVM models with kernel function my_kernel_linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.98\n",
      "Test accuracy  = 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy =\", round(svm_linear_kernel.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(svm_linear_kernel.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below, we replace the default kernel function with the gaussian kernel you wrote.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale',\n",
       "    kernel=<function my_kernel_gaussian at 0x00000232600D8708>, max_iter=-1,\n",
       "    probability=False, random_state=None, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_gaussian_kernel = SVC(kernel=my_kernel_gaussian)\n",
    "svm_gaussian_kernel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-20: print out the accuracy of SVM models with kernel function my_kernel_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 0.98\n",
      "Test accuracy  = 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy =\", round(svm_gaussian_kernel.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(svm_gaussian_kernel.score(X_test, y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm4:  Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okay, after above repetitive practices.  I would let you complete the whole training and testing process by yourself for decision tree. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-21: get data, split into traing data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, test_size=0.3 , random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-22: train a Decision Tree model using DecisionTreeClassifier in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "DTC = DecisionTreeClassifier()\n",
    "DTC.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-23: predict cancer on the test data using the trained Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = DTC.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Task-24: output the accuracies of the trained  logistic regression model on training data and test data respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy = 1.0\n",
      "Test accuracy  = 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy =\", round(DTC.score(X_train, y_train), 2))\n",
    "print(\"Test accuracy  =\", round(DTC.score(X_test, y_test),2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task-25: output the feature importances in this decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feauture:  0 , Score:  0.0\n",
      "Feauture:  1 , Score:  0.05073\n",
      "Feauture:  2 , Score:  0.0\n",
      "Feauture:  3 , Score:  0.0\n",
      "Feauture:  4 , Score:  0.0\n",
      "Feauture:  5 , Score:  0.0\n",
      "Feauture:  6 , Score:  0.0\n",
      "Feauture:  7 , Score:  0.07526\n",
      "Feauture:  8 , Score:  0.0\n",
      "Feauture:  9 , Score:  0.00161\n",
      "Feauture:  10 , Score:  0.0\n",
      "Feauture:  11 , Score:  0.00877\n",
      "Feauture:  12 , Score:  0.01028\n",
      "Feauture:  13 , Score:  0.0\n",
      "Feauture:  14 , Score:  0.0\n",
      "Feauture:  15 , Score:  0.0\n",
      "Feauture:  16 , Score:  0.0\n",
      "Feauture:  17 , Score:  0.03004\n",
      "Feauture:  18 , Score:  0.0\n",
      "Feauture:  19 , Score:  0.01044\n",
      "Feauture:  20 , Score:  0.0\n",
      "Feauture:  21 , Score:  0.02625\n",
      "Feauture:  22 , Score:  0.71418\n",
      "Feauture:  23 , Score:  0.00526\n",
      "Feauture:  24 , Score:  0.00493\n",
      "Feauture:  25 , Score:  0.0\n",
      "Feauture:  26 , Score:  0.01029\n",
      "Feauture:  27 , Score:  0.05195\n",
      "Feauture:  28 , Score:  0.0\n",
      "Feauture:  29 , Score:  0.0\n"
     ]
    }
   ],
   "source": [
    "feature_importances = DTC.feature_importances_\n",
    "for i,v in enumerate(feature_importances):\n",
    "    print('Feauture: ', i ,', Score: ',round(v,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### External NON-mandatory task (only if you have time and/or interest): using matplotlib.pyplot to visualize feature importance value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar([x for x in range(len(feature_importances))] , feature_importances)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Congratualtions if you run through above!  \n",
    "#### If you are already familar with the training process using Sklearn, feel free to try other settings to improve the accuracy.\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
